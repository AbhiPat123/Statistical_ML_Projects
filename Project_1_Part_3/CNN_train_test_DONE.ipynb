{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Import Libraries for this Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Only Numpy Library is necessary for this project and all the layers are compiled with Numpy.\n",
    "import numpy as np \n",
    "import pickle \n",
    "import sys\n",
    "import time\n",
    "import pdb          ### library for debugging\n",
    "np.random.seed(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Convolutional Layer Definition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolution2D:\n",
    "    # Initialization of convolutional layer\n",
    "    def __init__(self, inputs_channel, num_filters, kernel_size, padding, stride, learning_rate, name):\n",
    "        # weight size: (F, C, K, K)\n",
    "        # bias size: (F) \n",
    "        self.F = num_filters\n",
    "        self.K = kernel_size\n",
    "        self.C = inputs_channel\n",
    "\n",
    "        self.weights = np.zeros((self.F, self.C, self.K, self.K))\n",
    "        self.bias = np.zeros((self.F, 1))\n",
    "        for i in range(0,self.F):\n",
    "            self.weights[i,:,:,:] = np.random.normal(loc=0, scale=np.sqrt(1./(self.C*self.K*self.K)), size=(self.C, self.K, self.K))\n",
    "\n",
    "        self.p = padding\n",
    "        self.s = stride\n",
    "        self.lr = learning_rate\n",
    "        self.name = name\n",
    "    \n",
    "    # Padding Layer \n",
    "    def zero_padding(self, inputs, size):\n",
    "        w, h = inputs.shape[0], inputs.shape[1]\n",
    "        new_w = 2 * size + w\n",
    "        new_h = 2 * size + h\n",
    "        out = np.zeros((new_w, new_h))\n",
    "        out[size:w+size, size:h+size] = inputs\n",
    "        return out\n",
    "    \n",
    "    # Forward propagation\n",
    "    def forward(self, inputs):\n",
    "        # input size: (C, W, H)\n",
    "        # output size: (N, F ,WW, HH)\n",
    "        C = inputs.shape[0]\n",
    "        W = inputs.shape[1]+2*self.p\n",
    "        H = inputs.shape[2]+2*self.p\n",
    "        self.inputs = np.zeros((C, W, H))\n",
    "        for c in range(inputs.shape[0]):\n",
    "            self.inputs[c,:,:] = self.zero_padding(inputs[c,:,:], self.p)\n",
    "        WW = (W - self.K)//self.s + 1\n",
    "        HH = (H - self.K)//self.s + 1\n",
    "        feature_maps = np.zeros((self.F, WW, HH))\n",
    "        for f in range(self.F):\n",
    "            for w in range(WW):\n",
    "                for h in range(HH):\n",
    "                    feature_maps[f,w,h]=np.sum(self.inputs[:,w:w+self.K,h:h+self.K]*self.weights[f,:,:,:])+self.bias[f]\n",
    "\n",
    "        return feature_maps\n",
    "    \n",
    "    # Backward Propagation\n",
    "    def backward(self, dy):\n",
    "\n",
    "        C, W, H = self.inputs.shape\n",
    "        dx = np.zeros(self.inputs.shape)\n",
    "        dw = np.zeros(self.weights.shape)\n",
    "        db = np.zeros(self.bias.shape)\n",
    "\n",
    "        F, W, H = dy.shape\n",
    "        for f in range(F):\n",
    "            for w in range(W):\n",
    "                for h in range(H):\n",
    "                    dw[f,:,:,:]+=dy[f,w,h]*self.inputs[:,w:w+self.K,h:h+self.K]\n",
    "                    dx[:,w:w+self.K,h:h+self.K]+=dy[f,w,h]*self.weights[f,:,:,:]\n",
    "\n",
    "        for f in range(F):\n",
    "            db[f] = np.sum(dy[f, :, :])\n",
    "\n",
    "        self.weights -= self.lr * dw\n",
    "        self.bias -= self.lr * db\n",
    "        return dx\n",
    "    \n",
    "    # Function for extract the weights and bias for storage\n",
    "    def extract(self):\n",
    "        return {self.name+'.weights':self.weights, self.name+'.bias':self.bias}\n",
    "    \n",
    "    # Feed the pretrained weights and bias for models \n",
    "    def feed(self, weights, bias):\n",
    "        self.weights = weights\n",
    "        self.bias = bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: MaxPooling Layer Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Maxpooling2D:\n",
    "    # Initialization of MaxPooling layer\n",
    "    def __init__(self, pool_size, stride, name):\n",
    "        self.pool = pool_size\n",
    "        self.s = stride\n",
    "        self.name = name\n",
    "    \n",
    "    # Forward propagation\n",
    "    def forward(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        C, W, H = inputs.shape\n",
    "        new_width = (W - self.pool)//self.s + 1\n",
    "        new_height = (H - self.pool)//self.s + 1\n",
    "        out = np.zeros((C, new_width, new_height))\n",
    "        for c in range(C):\n",
    "            for w in range(W//self.s):\n",
    "                for h in range(H//self.s):\n",
    "                    out[c, w, h] = np.max(self.inputs[c, w*self.s:w*self.s+self.pool, h*self.s:h*self.s+self.pool])\n",
    "        return out\n",
    "    \n",
    "    # Backward propagation\n",
    "    def backward(self, dy):\n",
    "        C, W, H = self.inputs.shape\n",
    "        dx = np.zeros(self.inputs.shape)\n",
    "        \n",
    "        for c in range(C):\n",
    "            for w in range(0, W, self.pool):\n",
    "                for h in range(0, H, self.pool):\n",
    "                    st = np.argmax(self.inputs[c,w:w+self.pool,h:h+self.pool])\n",
    "                    (idx, idy) = np.unravel_index(st, (self.pool, self.pool))\n",
    "                    dx[c, w+idx, h+idy] = dy[c, w//self.pool, h//self.pool]\n",
    "        return dx\n",
    "    \n",
    "    # No weights and bias for pooling layer to store\n",
    "    def extract(self):\n",
    "        return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Fully-Connected Layer Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnected:\n",
    "    # Initialization of Fully-Connected Layer\n",
    "    def __init__(self, num_inputs, num_outputs, learning_rate, name):\n",
    "        self.weights = 0.01*np.random.rand(num_inputs, num_outputs)\n",
    "        self.bias = np.zeros((num_outputs, 1))\n",
    "        self.lr = learning_rate\n",
    "        self.name = name\n",
    "    \n",
    "    # Forward Propagation\n",
    "    def forward(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        return np.dot(self.inputs, self.weights) + self.bias.T\n",
    "    \n",
    "    # Backward Propagation\n",
    "    def backward(self, dy):\n",
    "\n",
    "        if dy.shape[0] == self.inputs.shape[0]:\n",
    "            dy = dy.T\n",
    "        dw = dy.dot(self.inputs)\n",
    "        db = np.sum(dy, axis=1, keepdims=True)\n",
    "        dx = np.dot(dy.T, self.weights.T)\n",
    "\n",
    "        self.weights -= self.lr * dw.T\n",
    "        self.bias -= self.lr * db\n",
    "\n",
    "        return dx\n",
    "    \n",
    "    # Extract weights and bias for storage\n",
    "    def extract(self):\n",
    "        return {self.name+'.weights':self.weights, self.name+'.bias':self.bias}\n",
    "    \n",
    "    # Feed the pretrained weights and bias for models \n",
    "    def feed(self, weights, bias):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "\n",
    "### Flatten function to convert 4D feature maps into 3D feature vectors\n",
    "class Flatten:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def forward(self, inputs):\n",
    "        self.C, self.W, self.H = inputs.shape\n",
    "        return inputs.reshape(1, self.C*self.W*self.H)\n",
    "    def backward(self, dy):\n",
    "        return dy.reshape(self.C, self.W, self.H)\n",
    "    def extract(self):\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Activation Function Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ReLU activation function\n",
    "class ReLu:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def forward(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        ret = inputs.copy()\n",
    "        ret[ret < 0] = 0\n",
    "        return ret\n",
    "    def backward(self, dy):\n",
    "        dx = dy.copy()\n",
    "        dx[self.inputs < 0] = 0\n",
    "        return dx\n",
    "    def extract(self):\n",
    "        return\n",
    "\n",
    "### Softmax activation function\n",
    "class Softmax:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def forward(self, inputs):\n",
    "        exp = np.exp(inputs, dtype=np.float)\n",
    "        self.out = exp/np.sum(exp)\n",
    "        return self.out\n",
    "    def backward(self, dy):\n",
    "        return self.out.T - dy.reshape(dy.shape[0],1)\n",
    "    def extract(self):\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Loss Function Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cross-Entropy Loss function\n",
    "def cross_entropy(inputs, labels):\n",
    "    out_num = labels.shape[0]\n",
    "    p = np.sum(labels.reshape(1,out_num)*inputs)\n",
    "    loss = -np.log(p)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Neural Network Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This step shows how to define a simple CNN with all kind of layers which we introduced above.\n",
    "\"\"\"\n",
    "class Net:\n",
    "    def __init__(self):\n",
    "        # input: 28x28\n",
    "        # output: 1x4 (only a subset, containing 4 classes, of the MNIST will be used)\n",
    "        # conv1:  {(28-5+0x0)/2+1} -> (12x12x6) (output size of convolutional layer)\n",
    "        # maxpool2: {(12-2)/2+1} -> (6x6)x6 (output size of pooling layer)\n",
    "        # fc3: 216 -> 32\n",
    "        # fc4: 32 -> 4\n",
    "        # softmax: 4 -> 4\n",
    "        lr = 0.001\n",
    "        self.layers = []\n",
    "        self.layers.append(Convolution2D(inputs_channel=1, num_filters=6, kernel_size=5, padding=0, stride=2, learning_rate=lr, name='conv1'))\n",
    "        self.layers.append(ReLu())\n",
    "        self.layers.append(Maxpooling2D(pool_size=2, stride=2, name='maxpool2'))\n",
    "        self.layers.append(Flatten())\n",
    "        self.layers.append(FullyConnected(num_inputs=6*6*6, num_outputs=32, learning_rate=lr, name='fc3'))\n",
    "        self.layers.append(ReLu())\n",
    "        self.layers.append(FullyConnected(num_inputs=32, num_outputs=4, learning_rate=lr, name='fc4'))\n",
    "        self.layers.append(Softmax())\n",
    "        self.lay_num = len(self.layers)\n",
    "    \n",
    "    ### Function for train the network\n",
    "    def train(self, data, label):\n",
    "        batch_size = data.shape[0]\n",
    "        loss = 0\n",
    "        acc = 0\n",
    "        for b in range(batch_size):\n",
    "            x = data[b]\n",
    "            y = label[b]\n",
    "            # forward pass\n",
    "            for l in range(self.lay_num):\n",
    "                output = self.layers[l].forward(x)\n",
    "                x = output\n",
    "            loss += cross_entropy(output, y)\n",
    "            if np.argmax(output) == np.argmax(y):\n",
    "                acc += 1\n",
    "            # backward pass\n",
    "            dy = y\n",
    "            for l in range(self.lay_num-1, -1, -1):\n",
    "                dout = self.layers[l].backward(dy)\n",
    "                dy = dout\n",
    "        return loss, acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8: Create your own subset samples of MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data......\n",
      "Preparing data......\n"
     ]
    }
   ],
   "source": [
    "from precode import *\n",
    "\"\"\"\n",
    "The subset of MNIST is created based on the last 4 digits of your ASUID. There are 4 categories and all returned \n",
    "samples are preprocessed and shuffled. \n",
    "\"\"\"\n",
    "print('Loading data......')\n",
    "sub_train_images, sub_train_labels, sub_test_images, sub_test_labels = init_subset('6522') # input your ASUID last 4 digits here to generate the subset samples of MNIST for training and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 9: Initial Network and do the Training and Testing process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "=== Iter:100 === Remain: 0 Hrs 1 Mins 12 Secs ===\n",
      "=== Iter:200 === Remain: 0 Hrs 1 Mins 8 Secs ===\n",
      "=== Iter:300 === Remain: 0 Hrs 1 Mins 4 Secs ===\n",
      "=== Iter:400 === Remain: 0 Hrs 1 Mins 3 Secs ===\n",
      "=== Iter:500 === Remain: 0 Hrs 0 Mins 57 Secs ===\n",
      "=== Iter:600 === Remain: 0 Hrs 0 Mins 53 Secs ===\n",
      "=== Iter:700 === Remain: 0 Hrs 0 Mins 50 Secs ===\n",
      "=== Iter:800 === Remain: 0 Hrs 0 Mins 48 Secs ===\n",
      "=== Iter:900 === Remain: 0 Hrs 0 Mins 45 Secs ===\n",
      "=== Iter:1000 === Remain: 0 Hrs 0 Mins 39 Secs ===\n",
      "=== Iter:1100 === Remain: 0 Hrs 0 Mins 36 Secs ===\n",
      "=== Iter:1200 === Remain: 0 Hrs 0 Mins 32 Secs ===\n",
      "=== Iter:1300 === Remain: 0 Hrs 0 Mins 29 Secs ===\n",
      "=== Iter:1400 === Remain: 0 Hrs 0 Mins 25 Secs ===\n",
      "=== Iter:1500 === Remain: 0 Hrs 0 Mins 21 Secs ===\n",
      "=== Iter:1600 === Remain: 0 Hrs 0 Mins 18 Secs ===\n",
      "=== Iter:1700 === Remain: 0 Hrs 0 Mins 14 Secs ===\n",
      "=== Iter:1800 === Remain: 0 Hrs 0 Mins 10 Secs ===\n",
      "=== Iter:1900 === Remain: 0 Hrs 0 Mins 7 Secs ===\n",
      "=== Iter:2000 === Remain: 0 Hrs 0 Mins 3 Secs ===\n",
      "=== Epoch:0 Train Size:2000, Train Acc:0.250, Train Loss:1.383 ===\n",
      "=== Epoch:0 Test Size:400, Test Acc:0.250, Test Loss:1.385 ===\n",
      "Epoch 1\n",
      "=== Iter:100 === Remain: 0 Hrs 1 Mins 12 Secs ===\n",
      "=== Iter:200 === Remain: 0 Hrs 1 Mins 8 Secs ===\n",
      "=== Iter:300 === Remain: 0 Hrs 1 Mins 4 Secs ===\n",
      "=== Iter:400 === Remain: 0 Hrs 1 Mins 1 Secs ===\n",
      "=== Iter:500 === Remain: 0 Hrs 0 Mins 57 Secs ===\n",
      "=== Iter:600 === Remain: 0 Hrs 0 Mins 54 Secs ===\n",
      "=== Iter:700 === Remain: 0 Hrs 0 Mins 50 Secs ===\n",
      "=== Iter:800 === Remain: 0 Hrs 0 Mins 47 Secs ===\n",
      "=== Iter:900 === Remain: 0 Hrs 0 Mins 43 Secs ===\n",
      "=== Iter:1000 === Remain: 0 Hrs 0 Mins 39 Secs ===\n",
      "=== Iter:1100 === Remain: 0 Hrs 0 Mins 35 Secs ===\n",
      "=== Iter:1200 === Remain: 0 Hrs 0 Mins 32 Secs ===\n",
      "=== Iter:1300 === Remain: 0 Hrs 0 Mins 28 Secs ===\n",
      "=== Iter:1400 === Remain: 0 Hrs 0 Mins 25 Secs ===\n",
      "=== Iter:1500 === Remain: 0 Hrs 0 Mins 21 Secs ===\n",
      "=== Iter:1600 === Remain: 0 Hrs 0 Mins 18 Secs ===\n",
      "=== Iter:1700 === Remain: 0 Hrs 0 Mins 14 Secs ===\n",
      "=== Iter:1800 === Remain: 0 Hrs 0 Mins 10 Secs ===\n",
      "=== Iter:1900 === Remain: 0 Hrs 0 Mins 7 Secs ===\n",
      "=== Iter:2000 === Remain: 0 Hrs 0 Mins 3 Secs ===\n",
      "=== Epoch:1 Train Size:2000, Train Acc:0.296, Train Loss:1.337 ===\n",
      "=== Epoch:1 Test Size:400, Test Acc:0.285, Test Loss:1.346 ===\n",
      "Epoch 2\n",
      "=== Iter:100 === Remain: 0 Hrs 1 Mins 12 Secs ===\n",
      "=== Iter:200 === Remain: 0 Hrs 1 Mins 8 Secs ===\n",
      "=== Iter:300 === Remain: 0 Hrs 1 Mins 4 Secs ===\n",
      "=== Iter:400 === Remain: 0 Hrs 1 Mins 1 Secs ===\n",
      "=== Iter:500 === Remain: 0 Hrs 0 Mins 57 Secs ===\n",
      "=== Iter:600 === Remain: 0 Hrs 0 Mins 55 Secs ===\n",
      "=== Iter:700 === Remain: 0 Hrs 0 Mins 50 Secs ===\n",
      "=== Iter:800 === Remain: 0 Hrs 0 Mins 47 Secs ===\n",
      "=== Iter:900 === Remain: 0 Hrs 0 Mins 43 Secs ===\n",
      "=== Iter:1000 === Remain: 0 Hrs 0 Mins 39 Secs ===\n",
      "=== Iter:1100 === Remain: 0 Hrs 0 Mins 36 Secs ===\n",
      "=== Iter:1200 === Remain: 0 Hrs 0 Mins 32 Secs ===\n",
      "=== Iter:1300 === Remain: 0 Hrs 0 Mins 29 Secs ===\n",
      "=== Iter:1400 === Remain: 0 Hrs 0 Mins 27 Secs ===\n",
      "=== Iter:1500 === Remain: 0 Hrs 0 Mins 21 Secs ===\n",
      "=== Iter:1600 === Remain: 0 Hrs 0 Mins 18 Secs ===\n",
      "=== Iter:1700 === Remain: 0 Hrs 0 Mins 14 Secs ===\n",
      "=== Iter:1800 === Remain: 0 Hrs 0 Mins 10 Secs ===\n",
      "=== Iter:1900 === Remain: 0 Hrs 0 Mins 7 Secs ===\n",
      "=== Iter:2000 === Remain: 0 Hrs 0 Mins 3 Secs ===\n",
      "=== Epoch:2 Train Size:2000, Train Acc:0.521, Train Loss:1.126 ===\n",
      "=== Epoch:2 Test Size:400, Test Acc:0.450, Test Loss:1.150 ===\n",
      "Epoch 3\n",
      "=== Iter:100 === Remain: 0 Hrs 1 Mins 12 Secs ===\n",
      "=== Iter:200 === Remain: 0 Hrs 1 Mins 9 Secs ===\n",
      "=== Iter:300 === Remain: 0 Hrs 1 Mins 3 Secs ===\n",
      "=== Iter:400 === Remain: 0 Hrs 1 Mins 2 Secs ===\n",
      "=== Iter:500 === Remain: 0 Hrs 0 Mins 59 Secs ===\n",
      "=== Iter:600 === Remain: 0 Hrs 0 Mins 55 Secs ===\n",
      "=== Iter:700 === Remain: 0 Hrs 0 Mins 50 Secs ===\n",
      "=== Iter:800 === Remain: 0 Hrs 0 Mins 46 Secs ===\n",
      "=== Iter:900 === Remain: 0 Hrs 0 Mins 43 Secs ===\n",
      "=== Iter:1000 === Remain: 0 Hrs 0 Mins 39 Secs ===\n",
      "=== Iter:1100 === Remain: 0 Hrs 0 Mins 36 Secs ===\n",
      "=== Iter:1200 === Remain: 0 Hrs 0 Mins 32 Secs ===\n",
      "=== Iter:1300 === Remain: 0 Hrs 0 Mins 28 Secs ===\n",
      "=== Iter:1400 === Remain: 0 Hrs 0 Mins 25 Secs ===\n",
      "=== Iter:1500 === Remain: 0 Hrs 0 Mins 21 Secs ===\n",
      "=== Iter:1600 === Remain: 0 Hrs 0 Mins 18 Secs ===\n",
      "=== Iter:1700 === Remain: 0 Hrs 0 Mins 14 Secs ===\n",
      "=== Iter:1800 === Remain: 0 Hrs 0 Mins 10 Secs ===\n",
      "=== Iter:1900 === Remain: 0 Hrs 0 Mins 7 Secs ===\n",
      "=== Iter:2000 === Remain: 0 Hrs 0 Mins 3 Secs ===\n",
      "=== Epoch:3 Train Size:2000, Train Acc:0.606, Train Loss:0.953 ===\n",
      "=== Epoch:3 Test Size:400, Test Acc:0.545, Test Loss:1.012 ===\n",
      "Epoch 4\n",
      "=== Iter:100 === Remain: 0 Hrs 1 Mins 12 Secs ===\n",
      "=== Iter:200 === Remain: 0 Hrs 1 Mins 9 Secs ===\n",
      "=== Iter:300 === Remain: 0 Hrs 1 Mins 4 Secs ===\n",
      "=== Iter:400 === Remain: 0 Hrs 1 Mins 1 Secs ===\n",
      "=== Iter:500 === Remain: 0 Hrs 0 Mins 57 Secs ===\n",
      "=== Iter:600 === Remain: 0 Hrs 0 Mins 54 Secs ===\n",
      "=== Iter:700 === Remain: 0 Hrs 0 Mins 50 Secs ===\n",
      "=== Iter:800 === Remain: 0 Hrs 0 Mins 47 Secs ===\n",
      "=== Iter:900 === Remain: 0 Hrs 0 Mins 43 Secs ===\n",
      "=== Iter:1000 === Remain: 0 Hrs 0 Mins 39 Secs ===\n",
      "=== Iter:1100 === Remain: 0 Hrs 0 Mins 36 Secs ===\n",
      "=== Iter:1200 === Remain: 0 Hrs 0 Mins 32 Secs ===\n",
      "=== Iter:1300 === Remain: 0 Hrs 0 Mins 29 Secs ===\n",
      "=== Iter:1400 === Remain: 0 Hrs 0 Mins 25 Secs ===\n",
      "=== Iter:1500 === Remain: 0 Hrs 0 Mins 21 Secs ===\n",
      "=== Iter:1600 === Remain: 0 Hrs 0 Mins 18 Secs ===\n",
      "=== Iter:1700 === Remain: 0 Hrs 0 Mins 14 Secs ===\n",
      "=== Iter:1800 === Remain: 0 Hrs 0 Mins 10 Secs ===\n",
      "=== Iter:1900 === Remain: 0 Hrs 0 Mins 7 Secs ===\n",
      "=== Iter:2000 === Remain: 0 Hrs 0 Mins 3 Secs ===\n",
      "=== Epoch:4 Train Size:2000, Train Acc:0.680, Train Loss:0.778 ===\n",
      "=== Epoch:4 Test Size:400, Test Acc:0.603, Test Loss:0.864 ===\n",
      "Epoch 5\n",
      "=== Iter:100 === Remain: 0 Hrs 1 Mins 12 Secs ===\n",
      "=== Iter:200 === Remain: 0 Hrs 1 Mins 8 Secs ===\n",
      "=== Iter:300 === Remain: 0 Hrs 1 Mins 4 Secs ===\n",
      "=== Iter:400 === Remain: 0 Hrs 1 Mins 2 Secs ===\n",
      "=== Iter:500 === Remain: 0 Hrs 0 Mins 58 Secs ===\n",
      "=== Iter:600 === Remain: 0 Hrs 0 Mins 54 Secs ===\n",
      "=== Iter:700 === Remain: 0 Hrs 0 Mins 50 Secs ===\n",
      "=== Iter:800 === Remain: 0 Hrs 0 Mins 46 Secs ===\n",
      "=== Iter:900 === Remain: 0 Hrs 0 Mins 44 Secs ===\n",
      "=== Iter:1000 === Remain: 0 Hrs 0 Mins 39 Secs ===\n",
      "=== Iter:1100 === Remain: 0 Hrs 0 Mins 36 Secs ===\n",
      "=== Iter:1200 === Remain: 0 Hrs 0 Mins 32 Secs ===\n",
      "=== Iter:1300 === Remain: 0 Hrs 0 Mins 28 Secs ===\n",
      "=== Iter:1400 === Remain: 0 Hrs 0 Mins 25 Secs ===\n",
      "=== Iter:1500 === Remain: 0 Hrs 0 Mins 21 Secs ===\n",
      "=== Iter:1600 === Remain: 0 Hrs 0 Mins 18 Secs ===\n",
      "=== Iter:1700 === Remain: 0 Hrs 0 Mins 14 Secs ===\n",
      "=== Iter:1800 === Remain: 0 Hrs 0 Mins 10 Secs ===\n",
      "=== Iter:1900 === Remain: 0 Hrs 0 Mins 7 Secs ===\n",
      "=== Iter:2000 === Remain: 0 Hrs 0 Mins 3 Secs ===\n",
      "=== Epoch:5 Train Size:2000, Train Acc:0.740, Train Loss:0.676 ===\n",
      "=== Epoch:5 Test Size:400, Test Acc:0.640, Test Loss:0.792 ===\n",
      "Epoch 6\n",
      "=== Iter:100 === Remain: 0 Hrs 1 Mins 14 Secs ===\n",
      "=== Iter:200 === Remain: 0 Hrs 1 Mins 9 Secs ===\n",
      "=== Iter:300 === Remain: 0 Hrs 1 Mins 4 Secs ===\n",
      "=== Iter:400 === Remain: 0 Hrs 1 Mins 1 Secs ===\n",
      "=== Iter:500 === Remain: 0 Hrs 0 Mins 57 Secs ===\n",
      "=== Iter:600 === Remain: 0 Hrs 0 Mins 56 Secs ===\n",
      "=== Iter:700 === Remain: 0 Hrs 0 Mins 50 Secs ===\n",
      "=== Iter:800 === Remain: 0 Hrs 0 Mins 47 Secs ===\n",
      "=== Iter:900 === Remain: 0 Hrs 0 Mins 44 Secs ===\n",
      "=== Iter:1000 === Remain: 0 Hrs 0 Mins 39 Secs ===\n",
      "=== Iter:1100 === Remain: 0 Hrs 0 Mins 35 Secs ===\n",
      "=== Iter:1200 === Remain: 0 Hrs 0 Mins 32 Secs ===\n",
      "=== Iter:1300 === Remain: 0 Hrs 0 Mins 28 Secs ===\n",
      "=== Iter:1400 === Remain: 0 Hrs 0 Mins 25 Secs ===\n",
      "=== Iter:1500 === Remain: 0 Hrs 0 Mins 21 Secs ===\n",
      "=== Iter:1600 === Remain: 0 Hrs 0 Mins 18 Secs ===\n",
      "=== Iter:1700 === Remain: 0 Hrs 0 Mins 14 Secs ===\n",
      "=== Iter:1800 === Remain: 0 Hrs 0 Mins 10 Secs ===\n",
      "=== Iter:1900 === Remain: 0 Hrs 0 Mins 7 Secs ===\n",
      "=== Iter:2000 === Remain: 0 Hrs 0 Mins 3 Secs ===\n",
      "=== Epoch:6 Train Size:2000, Train Acc:0.762, Train Loss:0.622 ===\n",
      "=== Epoch:6 Test Size:400, Test Acc:0.642, Test Loss:0.773 ===\n",
      "Epoch 7\n",
      "=== Iter:100 === Remain: 0 Hrs 1 Mins 12 Secs ===\n",
      "=== Iter:200 === Remain: 0 Hrs 1 Mins 10 Secs ===\n",
      "=== Iter:300 === Remain: 0 Hrs 1 Mins 5 Secs ===\n",
      "=== Iter:400 === Remain: 0 Hrs 1 Mins 2 Secs ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Iter:500 === Remain: 0 Hrs 0 Mins 57 Secs ===\n",
      "=== Iter:600 === Remain: 0 Hrs 0 Mins 55 Secs ===\n",
      "=== Iter:700 === Remain: 0 Hrs 0 Mins 50 Secs ===\n",
      "=== Iter:800 === Remain: 0 Hrs 0 Mins 46 Secs ===\n",
      "=== Iter:900 === Remain: 0 Hrs 0 Mins 44 Secs ===\n",
      "=== Iter:1000 === Remain: 0 Hrs 0 Mins 39 Secs ===\n",
      "=== Iter:1100 === Remain: 0 Hrs 0 Mins 36 Secs ===\n",
      "=== Iter:1200 === Remain: 0 Hrs 0 Mins 32 Secs ===\n",
      "=== Iter:1300 === Remain: 0 Hrs 0 Mins 29 Secs ===\n",
      "=== Iter:1400 === Remain: 0 Hrs 0 Mins 25 Secs ===\n",
      "=== Iter:1500 === Remain: 0 Hrs 0 Mins 21 Secs ===\n",
      "=== Iter:1600 === Remain: 0 Hrs 0 Mins 18 Secs ===\n",
      "=== Iter:1700 === Remain: 0 Hrs 0 Mins 14 Secs ===\n",
      "=== Iter:1800 === Remain: 0 Hrs 0 Mins 10 Secs ===\n",
      "=== Iter:1900 === Remain: 0 Hrs 0 Mins 7 Secs ===\n",
      "=== Iter:2000 === Remain: 0 Hrs 0 Mins 3 Secs ===\n",
      "=== Epoch:7 Train Size:2000, Train Acc:0.767, Train Loss:0.588 ===\n",
      "=== Epoch:7 Test Size:400, Test Acc:0.667, Test Loss:0.750 ===\n",
      "Epoch 8\n",
      "=== Iter:100 === Remain: 0 Hrs 1 Mins 13 Secs ===\n",
      "=== Iter:200 === Remain: 0 Hrs 1 Mins 8 Secs ===\n",
      "=== Iter:300 === Remain: 0 Hrs 1 Mins 4 Secs ===\n",
      "=== Iter:400 === Remain: 0 Hrs 1 Mins 1 Secs ===\n",
      "=== Iter:500 === Remain: 0 Hrs 0 Mins 57 Secs ===\n",
      "=== Iter:600 === Remain: 0 Hrs 0 Mins 54 Secs ===\n",
      "=== Iter:700 === Remain: 0 Hrs 0 Mins 50 Secs ===\n",
      "=== Iter:800 === Remain: 0 Hrs 0 Mins 47 Secs ===\n",
      "=== Iter:900 === Remain: 0 Hrs 0 Mins 43 Secs ===\n",
      "=== Iter:1000 === Remain: 0 Hrs 0 Mins 39 Secs ===\n",
      "=== Iter:1100 === Remain: 0 Hrs 0 Mins 36 Secs ===\n",
      "=== Iter:1200 === Remain: 0 Hrs 0 Mins 32 Secs ===\n",
      "=== Iter:1300 === Remain: 0 Hrs 0 Mins 29 Secs ===\n",
      "=== Iter:1400 === Remain: 0 Hrs 0 Mins 25 Secs ===\n",
      "=== Iter:1500 === Remain: 0 Hrs 0 Mins 21 Secs ===\n",
      "=== Iter:1600 === Remain: 0 Hrs 0 Mins 18 Secs ===\n",
      "=== Iter:1700 === Remain: 0 Hrs 0 Mins 14 Secs ===\n",
      "=== Iter:1800 === Remain: 0 Hrs 0 Mins 10 Secs ===\n",
      "=== Iter:1900 === Remain: 0 Hrs 0 Mins 7 Secs ===\n",
      "=== Iter:2000 === Remain: 0 Hrs 0 Mins 3 Secs ===\n",
      "=== Epoch:8 Train Size:2000, Train Acc:0.773, Train Loss:0.571 ===\n",
      "=== Epoch:8 Test Size:400, Test Acc:0.667, Test Loss:0.746 ===\n",
      "Epoch 9\n",
      "=== Iter:100 === Remain: 0 Hrs 1 Mins 13 Secs ===\n",
      "=== Iter:200 === Remain: 0 Hrs 1 Mins 11 Secs ===\n",
      "=== Iter:300 === Remain: 0 Hrs 1 Mins 5 Secs ===\n",
      "=== Iter:400 === Remain: 0 Hrs 1 Mins 1 Secs ===\n",
      "=== Iter:500 === Remain: 0 Hrs 0 Mins 57 Secs ===\n",
      "=== Iter:600 === Remain: 0 Hrs 0 Mins 53 Secs ===\n",
      "=== Iter:700 === Remain: 0 Hrs 0 Mins 50 Secs ===\n",
      "=== Iter:800 === Remain: 0 Hrs 0 Mins 46 Secs ===\n",
      "=== Iter:900 === Remain: 0 Hrs 0 Mins 43 Secs ===\n",
      "=== Iter:1000 === Remain: 0 Hrs 0 Mins 39 Secs ===\n",
      "=== Iter:1100 === Remain: 0 Hrs 0 Mins 36 Secs ===\n",
      "=== Iter:1200 === Remain: 0 Hrs 0 Mins 32 Secs ===\n",
      "=== Iter:1300 === Remain: 0 Hrs 0 Mins 28 Secs ===\n",
      "=== Iter:1400 === Remain: 0 Hrs 0 Mins 25 Secs ===\n",
      "=== Iter:1500 === Remain: 0 Hrs 0 Mins 21 Secs ===\n",
      "=== Iter:1600 === Remain: 0 Hrs 0 Mins 17 Secs ===\n",
      "=== Iter:1700 === Remain: 0 Hrs 0 Mins 14 Secs ===\n",
      "=== Iter:1800 === Remain: 0 Hrs 0 Mins 10 Secs ===\n",
      "=== Iter:1900 === Remain: 0 Hrs 0 Mins 7 Secs ===\n",
      "=== Iter:2000 === Remain: 0 Hrs 0 Mins 3 Secs ===\n",
      "=== Epoch:9 Train Size:2000, Train Acc:0.786, Train Loss:0.539 ===\n",
      "=== Epoch:9 Test Size:400, Test Acc:0.688, Test Loss:0.735 ===\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "epoch = 10            ### Default number of epochs\n",
    "batch_size = 100      ### Default batch size\n",
    "num_batch = sub_train_images.shape[0]/batch_size\n",
    "\n",
    "test_size = sub_test_images.shape[0]      # Obtain the size of testing samples\n",
    "train_size = sub_train_images.shape[0]    # Obtain the size of training samples\n",
    "\n",
    "### ---------- ###\n",
    "\"\"\"\n",
    "Please compile your own evaluation code based on the training code \n",
    "to evaluate the trained network.\n",
    "The function name and the inputs of the function have been predifined and please finish the remaining part.\n",
    "\"\"\"\n",
    "def evaluate(net, images, labels):\n",
    "    acc = 0    \n",
    "    loss = 0\n",
    "    batch_size = 1\n",
    "\n",
    "    pass\n",
    "    for batch_index in range(0, images.shape[0], batch_size):\n",
    "        \"\"\"\n",
    "        Please compile your main code here.\n",
    "        \"\"\"\n",
    "        # image x and label y\n",
    "        x = images[batch_index]\n",
    "        y = labels[batch_index]\n",
    "        \n",
    "        # run image through net\n",
    "        for l in range(net.lay_num):\n",
    "            output = net.layers[l].forward(x)\n",
    "            x = output\n",
    "        # compute loss for this image and increment\n",
    "        loss += cross_entropy(output, y)\n",
    "        if np.argmax(output) == np.argmax(y):\n",
    "            acc += 1\n",
    "    \n",
    "    # divide loss and accuracy by number of samples\n",
    "    loss = loss/images.shape[0]\n",
    "    acc = acc/images.shape[0]\n",
    "    return acc, loss\n",
    "\n",
    "### Start training process\n",
    "for e in range(epoch):\n",
    "    total_acc = 0    \n",
    "    total_loss = 0\n",
    "    print('Epoch %d' % e)\n",
    "    for batch_index in range(0, sub_train_images.shape[0], batch_size):\n",
    "        # batch input\n",
    "        if batch_index + batch_size < sub_train_images.shape[0]:\n",
    "            data = sub_train_images[batch_index:batch_index+batch_size]\n",
    "            label = sub_train_labels[batch_index:batch_index + batch_size]\n",
    "        else:\n",
    "            data = sub_train_images[batch_index:sub_train_images.shape[0]]\n",
    "            label = sub_train_labels[batch_index:sub_train_labels.shape[0]]\n",
    "        # Compute the remaining time\n",
    "        start_time = time.time()\n",
    "        batch_loss,batch_acc = net.train(data, label)  # Train the network with samples in one batch \n",
    "        \n",
    "        end_time = time.time()\n",
    "        batch_time = end_time-start_time\n",
    "        remain_time = (sub_train_images.shape[0]-batch_index)/batch_size*batch_time\n",
    "        hrs = int(remain_time/3600)\n",
    "        mins = int((remain_time/60-hrs*60))\n",
    "        secs = int(remain_time-mins*60-hrs*3600)\n",
    "        print('=== Iter:{0:d} === Remain: {1:d} Hrs {2:d} Mins {3:d} Secs ==='.format(int(batch_index+batch_size),int(hrs),int(mins),int(secs)))\n",
    "    \n",
    "    # Print out the Performance\n",
    "    train_acc, train_loss = evaluate(net, sub_train_images, sub_train_labels)  # Use the evaluation code to obtain the training accuracy and loss\n",
    "    test_acc, test_loss = evaluate(net, sub_test_images, sub_test_labels)      # Use the evaluation code to obtain the testing accuracy and loss\n",
    "    print('=== Epoch:{0:d} Train Size:{1:d}, Train Acc:{2:.3f}, Train Loss:{3:.3f} ==='.format(e, train_size,train_acc,train_loss))\n",
    "\n",
    "    print('=== Epoch:{0:d} Test Size:{1:d}, Test Acc:{2:.3f}, Test Loss:{3:.3f} ==='.format(e, test_size, test_acc,test_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
